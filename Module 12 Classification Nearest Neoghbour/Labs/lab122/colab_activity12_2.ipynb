{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-461a2bb27ab444fe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Colab Activity 12.2: Accuracy, Precision, and Recall\n",
    "\n",
    "**Expected Time: 60 Minutes**\n",
    "\n",
    "\n",
    "This activity focuses on differentiating between three classification metrics -- accuracy, precision, and recall.  Depending on the situation, you may have different perspectives.  In this assignment, you will use the scikit-learn metrics to evaluate and compare performance metrics.  In the next assignment, you will use confusion matrices to visually intuit these ideas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d992c68668ebdd29",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n",
    "- [Problem 5](#Problem-5)\n",
    "- [Problem 6](#Problem-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a2e3e4ca7dc600d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Your dataset for this problem will be a built-in dataset from scikitlearn containing measurements determined from images of breast cancer tumors and the label of malignant or benign.  There are 30 features and the target feature.  The data is loaded and split below. \n",
    "<p>Target = 0 means the cancer is malignant, Target = 1 means the cancer is benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cancer.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = np.where(df['target'] == 0, 'malignant', 'benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df, x = 'target')\n",
    "plt.title('Count of target observations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis = 1), df.target, \n",
    "                                                    random_state = 42,\n",
    "                                                   stratify = df.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2863deba924ec181",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Setting a Baseline\n",
    "\n",
    "\n",
    "\n",
    "It is always important to get in the habit of checking the baseline score for a classification model.  Here, when splitting the data, the `stratify` argument was used so that both the train and test set would have a similar proportion of classes.  This can be seen below.  Using this data, what is a baseline score for the model that predicts the majority class for all data points?  Enter your answer as a string to `baseline` below.\n",
    "\n",
    "```\n",
    "a) 37% accuracy\n",
    "b) 63% accuracy\n",
    "c) 50% accuracy\n",
    "d) 100% accuracy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "benign       0.629371\n",
       "malignant    0.370629\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "benign       0.626761\n",
       "malignant    0.373239\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba104599bdcf75e3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline = 'b'\n",
    "\n",
    "\n",
    "# Answer check\n",
    "print(baseline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9409d89e41b7239",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Pipeline for scaling and KNN\n",
    "\n",
    "\n",
    "\n",
    "To begin, create a pipeline `knn_pipe` with named steps `scale` and `knn` that uses the `StandardScaler` followed by the `KNeighborsClassifier` with `n_neighbors = 10`. Use the `fit` function on `knn_pipe` to train the pipeline on `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf877edbb803110f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;knn&#x27;, KNeighborsClassifier(n_neighbors=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=10)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('knn', KNeighborsClassifier(n_neighbors=10))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn_pipe = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 10))])\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Answer check\n",
    "knn_pipe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9da9732e2dda42cc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Evaluating your classifier\n",
    "\n",
    "\n",
    "\n",
    "Three scoring methods have been imported from scikit-learn that are used by comparing predictions to actual values.  Choose which method from `precision_score`, `recall_score`, and `accuracy_score` indicate fewer false positives (where a higher score means FEWER false positives). \n",
    "\n",
    "To achieve this, use the `precision_score` function with arguments `y_test` and `knn_pipe.predict(X_test)` and with `pos_label`  equal to `'malignant'`. Assign your result to `min_fp`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d0197b85df2cb969",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795918367346939\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn_pipe = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 10))])\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "min_fp = precision_score(y_test, knn_pipe.predict(X_test), pos_label = 'malignant')\n",
    "\n",
    "\n",
    "# Answer check\n",
    "print(min_fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ad92eeae259341d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Right kind of mistakes\n",
    "\n",
    "\n",
    "In this situation, which mistake is more detrimental to the patient if we attempt to use our algorithm to classify tumors as malignant or benign?  Would you rather avoid false positives or false negatives?  What metric does this mean we should use here? Enter your answer as a string to `best_metric` below -- `precision`, `recall`, or `accuracy`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6aaa8fe81bbb4d7b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_metric = 'recall'\n",
    "\n",
    "\n",
    "# Answer check\n",
    "print(best_metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c1a2df0d0ad78b4f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Improving a model based on specific metric\n",
    "\n",
    "\n",
    "\n",
    "Before, when using the `GridSearchCV` the best model has been selected using the default scoring method of the estimator.  You can change this behavior by passing an appropriate metric to the `scoring` argument. \n",
    "\n",
    "- Use the `map` function on `y_train` with an argument equal to `target_map`. Assign your result to `y_train_numeric`.\n",
    "- Use the `map` function on `y_test` with an argument equal to `target_map`. Assign your result to `y_test_numeric`.\n",
    "- Use the `GridSearchCV` function to implement a grid search on `knn_pipe` for odd numbers of neighbors from 1 to 21 where `recall` is the scoring metric used. Assign the result to `recall_grid`.\n",
    "- Use the `fit` function on `recall_grid` to train your model using `X_train` and `y_train_numeric`.\n",
    "- Use the `score` function on `recall_grid` to calculate the best model using `X_test` and  `y_test_numeric`. Assing your result to `best_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'malignant': 1, 'benign': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-56518a7f6dcaede8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is:  0.89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train_numeric = y_train.map(target_map)\n",
    "y_test_numeric = y_test.map(target_map)\n",
    "recall_grid = GridSearchCV(knn_pipe, param_grid = {'knn__n_neighbors': range(1, 23, 2)},\n",
    "                   scoring = 'recall')\n",
    "recall_grid.fit(X_train, y_train_numeric)\n",
    "best_score = recall_grid.score(X_test, y_test_numeric)\n",
    "\n",
    "\n",
    "# Answer check\n",
    "print(f'The best recall score is: {best_score: .2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb3e3fa1772b3d20",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Verifying the score\n",
    "\n",
    "\n",
    "Use your `recall_grid` to make predictions on the test data and assign to preds.  Use these predictions to count the number of false negatives and true positives.  Assign these as integers to `fn` and `tp` respectively below.  This should show that the grid search scoring method has been changed to recall.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91cd2d980bd4520d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall by hand is:  0.89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "recall_preds = recall_grid.predict(X_test)\n",
    "fn = 0\n",
    "tp = 0\n",
    "for i,j in zip(recall_preds, y_test_numeric):\n",
    "    if i == 0 and j == 1:\n",
    "        fn += 1\n",
    "    if i == 1 and j == 1:\n",
    "        tp += 1\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(f'Recall by hand is: {tp/(tp + fn): .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8162c9f910462ea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In other situations, a different metric may make sense.  Here, a specific kind of error -- labeling a cancerous tumor as not so -- is something we certainly want to avoid.  In the next activity, you will continue to consider these issues using confusion matrices to unpack the errors and how changing parameters of the estimator effects this."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
