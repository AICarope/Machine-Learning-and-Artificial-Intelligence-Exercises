{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-243c49e5aa3b4b42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Required Codio Assignment 22.1: Basic Neural Net for Image Data\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 30**\n",
    "\n",
    "This activity focuses on using a basic neural net architecture to predict handwritten digit labels.  Using the basic architecture you will also explore data augmentation using simple transformations of the images to create new data for the network.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "\n",
    "\n",
    "Run the code cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp312-cp312-win_amd64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 10.5/390.3 MB 54.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 22.8/390.3 MB 57.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 33.6/390.3 MB 56.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 40.1/390.3 MB 50.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 46.4/390.3 MB 46.9 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 52.2/390.3 MB 43.7 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 57.1/390.3 MB 40.5 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 62.1/390.3 MB 38.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 66.3/390.3 MB 36.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 71.6/390.3 MB 35.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 76.5/390.3 MB 34.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 81.5/390.3 MB 33.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 86.2/390.3 MB 33.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 91.2/390.3 MB 32.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 97.0/390.3 MB 32.1 MB/s eta 0:00:10\n",
      "   ---------- ---------------------------- 102.8/390.3 MB 31.8 MB/s eta 0:00:10\n",
      "   ---------- ---------------------------- 107.5/390.3 MB 31.3 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 112.5/390.3 MB 31.1 MB/s eta 0:00:09\n",
      "   ----------- --------------------------- 116.4/390.3 MB 30.5 MB/s eta 0:00:09\n",
      "   ------------ -------------------------- 120.6/390.3 MB 30.0 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 125.3/390.3 MB 29.6 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 130.8/390.3 MB 29.5 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 136.8/390.3 MB 29.5 MB/s eta 0:00:09\n",
      "   -------------- ------------------------ 143.1/390.3 MB 29.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------ 148.6/390.3 MB 29.5 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 154.4/390.3 MB 29.4 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 159.6/390.3 MB 29.3 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 163.8/390.3 MB 29.0 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 168.8/390.3 MB 28.8 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 174.6/390.3 MB 28.8 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 180.6/390.3 MB 28.9 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 186.9/390.3 MB 29.0 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 192.9/390.3 MB 28.9 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 198.2/390.3 MB 28.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 202.6/390.3 MB 28.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 205.3/390.3 MB 28.3 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 209.5/390.3 MB 28.1 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 213.6/390.3 MB 27.9 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 217.8/390.3 MB 27.7 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 222.3/390.3 MB 27.5 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 226.5/390.3 MB 27.4 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 230.9/390.3 MB 27.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 235.4/390.3 MB 27.1 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 239.3/390.3 MB 27.0 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 243.8/390.3 MB 26.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 248.0/390.3 MB 26.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 252.2/390.3 MB 26.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 256.1/390.3 MB 26.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 261.4/390.3 MB 26.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 266.9/390.3 MB 26.2 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 272.9/390.3 MB 26.0 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 279.2/390.3 MB 25.7 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 285.0/390.3 MB 25.5 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 290.7/390.3 MB 25.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 296.7/390.3 MB 25.0 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 301.7/390.3 MB 24.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 306.4/390.3 MB 24.8 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 311.7/390.3 MB 24.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 316.1/390.3 MB 24.7 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 320.3/390.3 MB 24.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 324.8/390.3 MB 24.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 329.8/390.3 MB 24.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 333.7/390.3 MB 24.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 338.4/390.3 MB 24.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 343.4/390.3 MB 24.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 348.1/390.3 MB 24.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.1/390.3 MB 24.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.1/390.3 MB 24.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 365.2/390.3 MB 24.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 371.7/390.3 MB 24.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 378.3/390.3 MB 24.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.8/390.3 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.3/390.3 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 23.6 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 25.8 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 23.0 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 6.3/26.4 MB 32.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.3/26.4 MB 30.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.6/26.4 MB 29.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.5/26.4 MB 28.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 27.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 25.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 27.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp312-cp312-win_amd64.whl (306 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 keras-3.9.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-387a69cad332020a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Dataset\n",
    "\n",
    "You will be using the `mnist` dataset which is included in the `datasets` module of the `keras` library. This dataset contains observations that are 28 x 28 pixel images of handwritten digits.  The labels correspond to the actual digit, forming a 10 category classification problem for you.  Below, the data is loaded and reshaped in anticipation of the neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.title(f'Image of a handwritten {y_train[0]}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-53f124e29bcf4258",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Using a Convolutional Architecture\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the TensorFlow function `Sequential()` to build a convolutional neural network using the following functions and configurations:\n",
    "\n",
    "- Use `Flatten` to flatten the images\n",
    "- Use a single `Dense` hidden layer with 60 nodes and a `relu` activation\n",
    "- Use a single `Dense` hidden layer with 10 nodes and a `softmax` activiation.\n",
    "\n",
    "Assign this network to the variable `model`.\n",
    "\n",
    "Compile `model` using `categorical_crossentropy` as your `loss` and  `accuracy` as your `metric`.\n",
    "\n",
    "Fit your model to the training data `X_train` and ` Y_train` including `X_test, Y_test` as your validation data. In this step, set the variable `verbose` equal to `0` and the number of `epochs` equal to 2.\n",
    "\n",
    "Assign the fit model to the `history` variable below.\n",
    "\n",
    "NOTE: This question is computationally expensive, so please be patient with the processing. It may take a few minutes based on your computing power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4632853de70a640a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8952833414077759\n",
      "0.9071000218391418\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "model = ''\n",
    "history = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "model = Sequential([Flatten(),\n",
    "                    Dense(60, activation = 'relu'),\n",
    "                   Dense(10, activation = 'softmax')])\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test),\n",
    "         verbose = 0, \n",
    "                   epochs = 2)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(history.history['accuracy'][-1])\n",
    "print(history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db6ba3091836a103",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Data Augmentation\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "One way to attempt a model improvement is to create new inputs to the network based on transformed versions of the original data.  \n",
    "\n",
    "\n",
    "In the code cell below, use the `ImageDataGenerator` function from `keras` with the arguments `horizontal_flip` and `vertical_flip` both equal to `True` to create a new version of the train and test data that performs both a horizontal and vertical flip of the images. Assign this new object to the variable `gen` below.  \n",
    "\n",
    "Perform the horizontal and vertical flips on the training sets by using the `.flow` method on `gen` with arguments `X_train` and `y_train`. Assign this new object to the variable `train_gen`.\n",
    "\n",
    "Perform the horizontal and vertical flips on the testing sets by using the `.flow` method on `gen` with arguments `X_test` and `y_test`. Assign this new object to the variable `test_gen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eefcd1f11f2f6718",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "gen = ''\n",
    "train_gen = ''\n",
    "test_gen = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "gen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "#gen.fit(X_train)\n",
    "train_gen = gen.flow(X_train, Y_train)\n",
    "test_gen = gen.flow(X_test, Y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "##UNCOMMENT TO VISUALIZE\n",
    "# fig, ax = plt.subplots(6, 6, figsize = (20, 14))\n",
    "# for i in range(6):\n",
    "#     for j in range(6):\n",
    "#         pic = train_gen.next()\n",
    "#         ax[i, j].imshow(pic[0][0].reshape(28, 28))\n",
    "# plt.suptitle(\"Augmented and Original Digit Data\", fontsize = 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a677cd10ec66bca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Training a model on the augmented data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, your aim is to compare the performance of the convolutional architecture on the augmented version of the data.  You can replace `X_train` and `X_test` in your model fitting with `train_gen` and `test_gen`.  \n",
    "\n",
    "Create a new model, `aug_model`, with the identical architecture to the first network in **Problem 1** and compile it using the same settings as in **Problem 1**.\n",
    "\n",
    "This time, fit your model to the data `train_gen` defined in **Problem 2** and use `test_gen` as `validation_data`. In this step, set the variable `verbose` equal to `0` and the number of `epochs` equal to 2.\n",
    "\n",
    "Assign the fit model to the `augmented_history` variable below.\n",
    "\n",
    "NOTE: This question is computationally expensive, so please be patient with the processing. It may take a few minutes based on your computing power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2058f00cf54b6027",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6123833060264587\n",
      "0.6575000286102295\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "aug_model = ''\n",
    "augmented_history = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "aug_model = Sequential([Flatten(), Dense(60, activation = 'relu'),\n",
    "                       Dense(10, activation = 'softmax')])\n",
    "aug_model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "augmented_history = aug_model.fit(train_gen,  validation_data = test_gen,\n",
    "                                 epochs = 2, verbose = 0)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(augmented_history.history['accuracy'][-1])\n",
    "print(augmented_history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e5311135bb2467c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note the performance difference and think about why it either improved or declined after using the augmented data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
