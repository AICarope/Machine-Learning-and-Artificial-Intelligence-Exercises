{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a474b03adc92ca8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Required Codio Assignment 22.2: Convolutional Neural Network\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 40**\n",
    "\n",
    "This activity focuses on using a basic convolutional architecture to predict handwritten digits from the `mnist` dataset.  Your goal is to again use the preprocessing tools of `keras` to prepare the data.  Next, you will use the `Conv2D` and `MaxPool2D` layers to create the feature maps of digits.   Finally, you will flatten the resulting feature maps and pass them through a conventional dense architecture.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "\n",
    "Run the code cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.13.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.38.4)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp311-cp311-win_amd64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp311-cp311-win_amd64.whl (390.2 MB)\n",
      "   ---------------------------------------- 0.0/390.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 6.6/390.2 MB 33.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 12.3/390.2 MB 30.8 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 17.8/390.2 MB 30.3 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 22.3/390.2 MB 27.6 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 27.0/390.2 MB 26.7 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 32.0/390.2 MB 26.3 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 36.4/390.2 MB 26.0 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 41.4/390.2 MB 25.6 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 46.9/390.2 MB 26.0 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 51.4/390.2 MB 25.6 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 56.6/390.2 MB 25.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 61.6/390.2 MB 25.5 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 66.3/390.2 MB 25.3 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 70.8/390.2 MB 25.2 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 75.8/390.2 MB 25.0 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 79.7/390.2 MB 24.8 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 84.7/390.2 MB 24.7 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 89.1/390.2 MB 24.5 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 93.1/390.2 MB 24.3 MB/s eta 0:00:13\n",
      "   --------- ------------------------------ 97.3/390.2 MB 24.2 MB/s eta 0:00:13\n",
      "   ---------- ---------------------------- 101.2/390.2 MB 23.9 MB/s eta 0:00:13\n",
      "   ---------- ---------------------------- 105.4/390.2 MB 23.8 MB/s eta 0:00:12\n",
      "   ----------- --------------------------- 110.1/390.2 MB 23.8 MB/s eta 0:00:12\n",
      "   ----------- --------------------------- 115.6/390.2 MB 23.9 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 121.9/390.2 MB 24.2 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 127.7/390.2 MB 24.4 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 131.6/390.2 MB 24.2 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 135.3/390.2 MB 24.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 140.2/390.2 MB 24.0 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 145.2/390.2 MB 24.0 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 150.2/390.2 MB 24.0 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 155.2/390.2 MB 24.0 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 160.4/390.2 MB 24.1 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 164.6/390.2 MB 24.0 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 168.8/390.2 MB 23.9 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 173.3/390.2 MB 24.0 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 177.5/390.2 MB 23.8 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 181.9/390.2 MB 23.7 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 186.4/390.2 MB 23.7 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 191.6/390.2 MB 23.7 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 197.9/390.2 MB 23.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 203.2/390.2 MB 24.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 208.9/390.2 MB 24.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 215.2/390.2 MB 24.2 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 220.7/390.2 MB 24.3 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 226.5/390.2 MB 24.4 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 232.5/390.2 MB 24.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 238.3/390.2 MB 24.6 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 243.5/390.2 MB 24.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 249.3/390.2 MB 24.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 255.3/390.2 MB 24.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 259.0/390.2 MB 24.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 264.5/390.2 MB 24.6 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 269.7/390.2 MB 24.5 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 274.5/390.2 MB 24.5 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 279.4/390.2 MB 24.4 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 283.4/390.2 MB 24.4 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 287.8/390.2 MB 24.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 293.3/390.2 MB 24.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 299.1/390.2 MB 24.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 304.3/390.2 MB 24.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 309.1/390.2 MB 24.5 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 314.3/390.2 MB 24.5 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 318.5/390.2 MB 24.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 323.5/390.2 MB 24.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 327.7/390.2 MB 24.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 332.7/390.2 MB 24.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 338.2/390.2 MB 24.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 343.7/390.2 MB 24.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 348.9/390.2 MB 24.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 353.6/390.2 MB 24.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 357.0/390.2 MB 24.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 361.5/390.2 MB 24.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 366.5/390.2 MB 24.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 370.4/390.2 MB 24.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 375.1/390.2 MB 24.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 379.1/390.2 MB 24.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.8/390.2 MB 24.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  388.2/390.2 MB 24.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.2 MB 24.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.2 MB 24.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.2 MB 24.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.2/390.2 MB 23.0 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 15.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading h5py-3.13.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 19.2 MB/s eta 0:00:00\n",
      "Using cached keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Downloading numpy-2.0.2-cp311-cp311-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 4.5/15.9 MB 24.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.9/15.9 MB 20.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.1/15.9 MB 19.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.5/15.9 MB 19.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 18.9 MB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.4 MB/s eta 0:00:00\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp311-cp311-win_amd64.whl (305 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, rich, ml-dtypes, h5py, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.13.0 keras-3.9.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.1 protobuf-5.29.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 2.0.2 which is incompatible.\n",
      "scipy 1.11.1 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.0.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\numpy\\_typing\\_scalars.py:12: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  _BoolLike_co = Union[bool, np.bool]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26224\\1709952267.py\", line 4, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 30, in <module>\n",
      "    from numpy import typing as npt\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\numpy\\typing\\__init__.py\", line 158, in <module>\n",
      "    from numpy._typing import (\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\numpy\\_typing\\__init__.py\", line 151, in <module>\n",
      "    from ._scalars import (\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\numpy\\_typing\\_scalars.py\", line 12, in <module>\n",
      "    _BoolLike_co = Union[bool, np.bool]\n",
      "                               ^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py\", line 305, in __getattr__\n",
      "AttributeError: module 'numpy' has no attribute 'bool'.\n",
      "`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9aa66c18a13a5ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Loading the Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the function `load_data()` on the `mnist` dataset to load the dataset. Assign your dataset to the variable `(X_train, Y_train), (X_test, Y_test)` below.\n",
    "\n",
    "Use the function `reshape` on `X_train` to reshape the training data in anticipation of the convolutional layers: set the arguments of the function `reshape ` equal to `(60_000, 28, 28, 1)`.  Assign this object to `X_train`.\n",
    "\n",
    "Use the function `reshape` on `X_test` to reshape the testing data in anticipation of the convolutional layers: set the arguments of the function `reshape ` equal to `(10_000, 28, 28, 1)`.  Assign this object to `X_test`.\n",
    "\n",
    "\n",
    "Create an `ImageDataGenerator` object with the argument `rescale = 1/255.` and assign to the variable `gen`.  \n",
    "\n",
    "Use the function `to_categorical` to convert the training and testing target variables. Assign these new objects to `Y_train` and `Y_test`, respectively.\n",
    "\n",
    "Use the `.flow()` function on the generator `gen`  with the reshaped and dummied `X_train` and `Y_train` to create the `train_gen` object.\n",
    "\n",
    "Use the `.flow()` function on the generator `gen`  with the reshaped and dummied `X_test` and `Y_test` to create the `test_gen` object.\n",
    "\n",
    "\n",
    "NOTE: This question is computationally expensive, so please be patient with the processing. It may take a few minutes based on your computing power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1d50e9a681ee148",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### GRADED\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m (X_train, Y_train), (X_test, Y_test) \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "(X_train, Y_train), (X_test, Y_test) = ('', ''), ('', '')\n",
    "X_train = ''\n",
    "X_test = ''\n",
    "gen = ''\n",
    "Y_train = ''\n",
    "Y_test = ''\n",
    "train_gen = ''\n",
    "test_gen = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60_000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10_000, 28, 28, 1)\n",
    "gen = ImageDataGenerator(rescale=1/255.)\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "train_gen = gen.flow(X_train, Y_train)\n",
    "test_gen = gen.flow(X_test, Y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(train_gen)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34783f2dfd989506",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Constructing the Convolutional Layers\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, create a neural network named `conv_model` using the following architecture:\n",
    "\n",
    "- One `Conv2D` layer with 16 filters and a kernel of size equal to 3 x 3 with `relu` activation\n",
    "- One `MaxPool2D` layer with pool size equal to 2 x 2\n",
    "- One `Flatten` layer to flatten the results of pooling\n",
    "- One `Dense` layer with 50 nodes and `relu` activation\n",
    "- One `Dense` output layer 10 noded and with `softmax` activation\n",
    "\n",
    "Compile `conv_model` using `categorical_crossentropy` as your `loss` and  `accuracy` as your `metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f8f26477939a464f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (60000, 26, 26, 16)       160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (60000, 13, 13, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (60000, 2704)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (60000, 50)               135250    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (60000, 10)               510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,920\n",
      "Trainable params: 135,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 17:11:55.397224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-04-19 17:11:55.397266: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-19 17:11:55.397294: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (channelround-ingridnancy): /proc/driver/nvidia/version does not exist\n",
      "2023-04-19 17:11:55.397765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "conv_model = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "conv_model = Sequential([Conv2D(filters = 16, kernel_size = (3, 3), activation = 'relu'),\n",
    "                   MaxPool2D(pool_size = (2, 2)),\n",
    "                   Flatten(),\n",
    "                   Dense(50, activation = 'relu'),\n",
    "                   Dense(10, activation = 'softmax')])\n",
    "conv_model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "conv_model.build(input_shape = (X_train.shape[0], 28, 28, 1))\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-09b50273ad58e8cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Examining the Training\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Use the `fit()` function on `conv_model` to fit the reshaped training data `train_gen`. Set the argument `validation_data` equal to `test_gen`, the argument `epochs` equal to 1, and the argument `verbose` equal to 0.  Assign the result to the variable `history` below. Feel free to uncomment the code to visualize the resulting fit accuracies.\n",
    "\n",
    "NOTE: This question is computationally expensive, so please be patient with the processing. It may take a few minutes based on your computing power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acfe9761b7454a3f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "history = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "history = conv_model.fit(train_gen, validation_data=test_gen, epochs=1, verbose = 0)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "#plt.plot(history.history['accuracy'], label = 'Train')\n",
    "#plt.plot(history.history['val_accuracy'], label = 'Test')\n",
    "#plt.grid()\n",
    "#plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-478b565563eb3bd2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Predicting with a New Image\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "\n",
    "Below, we have defined the object `test_images` for you with 5 observations. \n",
    "\n",
    "Use the function `reshape` on `test_images` with argument equal to `(num_observations, 28, 28, 1)`. Assign this new object to `test_images_shaped`.\n",
    "\n",
    "Next, use the function `predict()` on the `conv_model` object with argument equal to `test_images_shaped`. Use the function NumPy  function `argmax` to retrieve the indices of the maximum elements in the array along the `axis` 1.\n",
    "Assign the result to the variable `preds`.\n",
    "\n",
    "HINT: The pseudocode for this last step is given below:\n",
    "\n",
    "```Python\n",
    "preds = np.argmax(conv_model.predict(...), axis = ...)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ebb9c10dc4397d9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step\n",
      "[7 2 1 0 4]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tf.random.set_seed(42)\n",
    "test_images = X_test[:5]\n",
    "preds = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tf.random.set_seed(42)\n",
    "test_images_shaped = test_images.reshape(5, 28, 28, 1)\n",
    "preds = np.argmax(conv_model.predict(test_images_shaped), axis = 1)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(preds)\n",
    "# fig, ax = plt.subplots(1, 5, figsize = (20, 4))\n",
    "# for i, im in enumerate(test_images):\n",
    "#     ax[i].imshow(im.reshape(28, 28))\n",
    "#     ax[i].set_title(f'Prediction: {preds[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
