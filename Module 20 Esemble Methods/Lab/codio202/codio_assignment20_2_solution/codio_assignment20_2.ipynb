{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e6724797402a4be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Required Codio Assignment 20.2: Implementing Bagging\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 50**\n",
    "\n",
    "This activity focuses on using the `BaggingClassifier`.  You will use the Scikit-Learn implementation to compare performance on the fetal health dataset to that of the other models in the module -- Random Forests, Adaptive Boosting, and Gradient Boosting. The `BaggingClassifier` is a meta estimator that will aggregate estimators built on samples of the data.  You are to specify certain estimators and samples to become familiar with the functionality of the estimator and the variations you can produce with important arguments.  \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c49cddcd44fd7d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Data and Documentation\n",
    "\n",
    "Below the data is loaded and prepared.  For this exercise, you will be expected to consult the documentation on the `BaggingClassifier` [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator).  The vocabulary in each problem can be found in the documentation and you are expected to use the correct settings for the arguments as a result of reading the documentation.  For each model, be sure to set `random_state = 42`.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fetal.zip', compression = 'zip')\n",
    "X, y = df.drop('fetal_health', axis = 1), df['fetal_health']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4a9290546050a63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Aggregating bootstrap models\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To start, create an ensemble of a decision tree using the `BaggingClassifier` function with `random_state = 42`. Fit this model to the training data `X_train` and `y_train`. Assign this moel to `bagged_model`.\n",
    "\n",
    "Next, use the `score` function on `bagged_model` to calculate the performance on the test data. Assign this value to `bagged_score`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c19eb5f000426b4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9511278195488722\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "bagged_model = ''\n",
    "bagged_score = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "bagged_model = BaggingClassifier(random_state=42).fit(X_train, y_train)\n",
    "bagged_score = bagged_model.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(bagged_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f36f23cde3504a9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Pasting vs. Bagging\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "\n",
    "\n",
    "Create an ensemble of a decision tree using the `BaggingClassifier` function with `random_state = 42`. Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument of `BaggingClassifier` to change from **bagging** to **pasting**. Fit this model to the training data `X_train` and `y_train`. Assign this moel to `pasted_model`.\n",
    "\n",
    "Next, use the `score` function on `pasted_model` to calculate the performance on the test data. Assign this value to `pasted_score`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ead12c3abd052f0f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9379699248120301\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "pasted_model = ''\n",
    "pasted_score = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "pasted_model = BaggingClassifier(random_state=42, \n",
    "                                bootstrap=False).fit(X_train, y_train)\n",
    "pasted_score = pasted_model.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(pasted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e658a1750560496",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Random Subspaces\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "\n",
    "\n",
    "Create an ensemble of a decision tree using the `BaggingClassifier` function with `random_state = 42`. Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument to change from **bagging** to **random subspaces** with at most 10 features sampled. Fit this model to the training data `X_train` and `y_train`. Assign this moel to `subspace_model`.\n",
    "\n",
    "Next, use the `score` function on `subspace_model` to calculate the performance on the test data. Assign this value to `subspace_score`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dca845cff278bad8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943609022556391\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "subspace_model = ''\n",
    "subspace_score = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "subspace_model = BaggingClassifier(random_state=42, \n",
    "                                bootstrap=False, \n",
    "                                  max_features=10).fit(X_train, y_train)\n",
    "subspace_score = subspace_model.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(subspace_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-03e0faf6fb6f14b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Random Patches\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Create an ensemble of a decision tree using the `BaggingClassifier` function with `random_state = 42`. Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and adjust the appropriate argument to change from **bagging** to **random patches**. Use no more than 30% of the data and no more than 10 features in your samples. Assign this moel to `patches_model`.\n",
    "\n",
    "Next, use the `score` function on `patches_model` to calculate the performance on the test data. Assign this value to `patches_score`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a70c410a6884470",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9304511278195489\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "patches_model = ''\n",
    "patches_score = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "patches_model = BaggingClassifier(random_state=42, \n",
    "                                bootstrap=False, \n",
    "                                  max_features=10,\n",
    "                                 max_samples=0.3).fit(X_train, y_train)\n",
    "patches_score = patches_model.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(patches_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6763bbf860939634",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Nature of the Tree Models\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consult the documentation [here](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator) and observe whether or not bagging typically works with simple or complex tree models.  Enter your answer as `simple` or `complex` as a string to `ans5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-557f28e1d6225695",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ans5 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "ans5 = 'complex'\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
